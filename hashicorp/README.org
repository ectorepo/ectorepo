#+TITLE:     Ectorepo: Hashicorp Core
#+AUTHOR:    David Conner
#+EMAIL:     aionfork@gmail.com
#+DESCRIPTION: notes

The docs are now greppable. I wish I had realized this sooner.

* Hashicorp
** Terraform

For Terraform, there's [[https://github.com/staticaland/terraform-generate-snippets][staticaland/terraform-generate-snippets]], which
autogenerates snippets from =terraform providers schema -json=

** Vault

** Packer

** Nomad

** Consul

** Vagrant

* Automation

*.envrc.eg*

#+begin_src sh :tangle .envrc.eg
use_guix_manifest manifest.scm
#+end_src

*manifest.scm*

#+begin_src scheme :tangle manifest.scm
(use-modules (gnu packages python-xyz))

;; (concatenate-manifests ... )
;; package->development-manifest only returns the `guix shell -D` dependencies
;; just add python-lsp-server for now

(specifications->manifest
 '("python"
   "python-scrapy"
   "python-lsp-server"))
#+end_src

** GCP

There is a scrapy project in =./scraping= to create XML from [[https://cloud.google.com/docs/terraform/blueprints/terraform-blueprints][GCP Terraform
Blueprints]]. Perhaps [[https://www.crummy.com/software/BeautifulSoup/bs4/doc/][beautifulsoup]] was more appropriate for this. It's not
quite complete and requires some manual work. See below under "Misc."

*** Blueprints

From the =hashicorp/scraping= directory.

#+begin_src sh
# this skips a few with http:/// and etc.
scrapy runspider scraping/spiders/gcp_tf_blueprints.py -O output/repos.json
yq -y '. | sort_by(.project.name)' "output/repos.json" > output/repos.yml
#+end_src

I'm not too sure the =xq= command is suited to setting attributes on a tag,
instead of writing them to the nodes' children. So for now, this requires
manually transforming the output with regexp.

Since the GraphQL pipeline is not working either (it req. ~70 Github API
requests per try, naively, and these are limited). So to validate, commit the
=gcp_blueprints.xml= changes, which are sorted ... and see which repo's don't
clone.

**** Misc

Getting =defaultBranchRef= from a list of repositories req. calling this query
later in a Scrapy [[https://docs.scrapy.org/en/latest/topics/item-pipeline.html][RepositoryPipeline]] (see [[https://gql.readthedocs.io/en/latest/async/async_usage.html#async-usage][gql example for async usage]])

#+begin_example graphql
query {
  repository(owner:"octocat", name:"Hello-World") {
    title
    url
    owner{login}
    name
    defaultBranchRef{prefix name}
    url
    updatedAt
    isArchived
  }
 }
#+end_example
