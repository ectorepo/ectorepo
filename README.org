:PROPERTIES:
:ID:       4554d87c-498f-4acd-b7ef-500714e6b7b7
:END:
#+TITLE: Ectorepo Notes
#+AUTHOR: David Conner
#+DESCRIPTION: Git submodules containing Google Repo manifests for a great good.
#+PROPERTY:
#+STARTUP: content
#+OPTIONS: toc:nil

*** IDEA Use [[https://github.com/magit/orgit][magit/orgit's orgit-rev]] for links to code in the repo
+ This allows you to make org links to files that get exported as HTTP URL's to the same file in their their remotes
+ =$ORG_ROAM/code= :: contains links named =fdsa.org= out to =$REPO/fdsa/README.org= or =$REPO/fdsa/code.org= files
+ =$REPO= :: contains the repo manifests & =code.org= files.
  - directory should be a sibling to =$ORG_ROAM=
+ =$ECTO= :: contains the synced repos
  - directory should also be a sibling to =$ORG_ROAM=

*** TODO plan on exploring Linux gui's with ectorepo/sway, then gradually migrate to new repo XML
+ [ ] something like ectorepo/guiland
*** TODO find out how to deal with sourcehut's URL stcture
+ the package [[https://github.com/rmuslimov/browse-at-remote][browse-at-remote]] should demonstrate how to handle the tilde

* Ectorepo

This is a git repo full of submodules to [[https://android.googlesource.com/tools/repo][Repo]] [[https://android.googlesource.com/platform/manifest/][projects]] made of git repos. The
capital R in Repo matters. Technically, this can be done with HTTPS and an XML
manifest server ... but I'm special. I'll be using git submodules.

** What is a Git Playlist, Trebek

I've created this organization to separate these "git playlist" manifest repos
from my own Github. And I've created this project for me personally. Expect
77incomplete documentation and such. The power of google Repo could be in your
hands. There is almost zero documentation avaiable for it on the web. It
downloads a copy of its own python scripts. That's your best bet. That, or this
repo.

[[file:./img/sean-connery.jpg]]

** Caveats

#+begin_quote
I've just started to use Google Repo, so I'm not exactly an expert.
#+end_quote

Further, I won't exactly be using Repo to solve the problems that it is designed
to address. It's a bit heavy handed for what I want, but for git & VC automation
I'd rather invest my time learning an over-engineered tool. Google repo is a
devops tool developed for Android and Chromium OS that is used for
automation/instrumentation/hooks of builds and tests. These projects are massive
and involve collaboration of thousands of developers. To make matters more
complicated, both Android and Chromium OS need to support legacy
hardware/software. So Repo allows developers to specify manifest branches that
pin specific subproject branchs for various build scenarios.

And the next thing you'll be learning in your Google onboarding is why C++
compiler design could not be rectified for the scale of software Google was
building, necessitating =Go= and =bazel=. But the real question there is =Why=
-- for which any sufficiently technical answer affirmatively deserves an
"Achievment Unlocked" next to that "Arctic Code Repository" badge of yours.

Bonus points if you manage to explain it using these [[https://www.youtube.com/watch?v=HeQX2HjkcNo][Peano Arithmatic cards]].

#* Table of Contents :TOC_2_gh:

* Getting Started

You'll probably want to use =ssh-agent= in whichever way you do that.

** Doing your first =repo sync=

1. Install Google Repo with something like =sudo pacman -Syu repo=
2. Get a manifest.xml via:
   + Specifying a manifest repo with a =default.xml=.
   + Cloning a repo with a manifest XML definition.
   + Building a manifest XML according to Google's Manifest DTD.
3. Do a =repo init= via:
   + Manifest Git or XML URL: =repo init -u $URL=
   + File: =repo init -m $XML_FILE=
4. Do a =repo sync= and, even if your XML is all good, you'll probably run into
   branch naming issues... /this is why we can't have nice things/.
5. Update the XML =<defaults/>= and =<project/>= tags with the appropriate
   =revision= properties. Then cross your fingers and try =repo sync= once
   again... /just be glad you're not Google devops or a Google VP/.

** Using the manifest repositories in this project

You have three options to start with:

1. If you want all the manifest repo's (and you probably don't) -- clone this
   repo, then init/update the submodules. Then cd to the file locations of your
   choice and run =repo sync -m $XML_FILE=
2. Clone the manifests for groups of git repo's that you want using =repo sync
   -u $URL=. This is what I would recommend, initially, as large repos like
   Android or ChromiumOS can require 10+ gigabytes if you don't use additional
   =repo sync= options.
3. Use the org-babel blocks below to cobble together a manifest using an
   existing set of git repositories. You can use =repo sync= with the =-m
   $XML_FILE= option when building the manifest or =-u $URL= option if you'd
   prefer to push it to a git remote.
   - These won't account for git submodules and other edge cases.
   - I developed these examples for my purposes on my systems.
   - You will likely have to iterate a few times to get Google repo to ingest
     your manifest as intended If you end up importing more

**** TODO examples using =dir-locals.el= with Repo & org-mode

** Running =repo sync= on Guix System

The guix git-repo package currently has some issues with =python3=. This should
fix running =repo= in =/data/ecto=, the common directory where repos are synced.
It should only needed on Guix System as a temporary fix. I would perhaps
contribute a patch, but I'm too busy at the moment. I'm not sure if it's a
simple fix.

#+begin_src sh :tangle .envrc.ecto.eg
# -*- mode: sh -*-
use_guix_profile $GUIX_EXTRA/pythondev/pythondev
PATH_add /data/ecto/git-repo
layout python3
#+end_src

* Automation and Tooling

Please excuse the messiness. The code here is not intended to be redistributed
and everything would be clean if it was. I'm experimenting with a lot of things
and I don't see a lot of people using =git-repo= online.

I have a lot of fleeting ideas that are based on the circumstances which don't
extend out to cover a lot of cases. I just need to get the list of repositories
into sorted/uniqued XML to make it easier to maintain for me personally.

I like the idea of things "bubbling up" in priority. For example:

+ Once you do something 3 times, then you automate.
+ Your TODO's enter this file and then are refiled closer to more permanent
  files/headlines.
+ It starts in github.com/ectorepo/ectorepo as a directory with an intended
  potential migration path to submodule, which is a bit easier to change out as
  a branch or to socialize for collaboration (which will basically never happen)
+ In this case: give some scripts an isolated environment, then later figure out
  how to make that environment robust to multiple platforms or to sharing across
  multiple projects.

This avoids forcing me to think too much about configuration management,
esp. for multiple environments, before I experience the first-order and
second-order complications of some process.

+ I would like to ideate the later intended migration paths, but only surface
  level details. So if classes/scripts need to be shared, they're trivial to
  integrate, but I only want to spend like 5 minutes thinking about this.
+ The other type of details to consider (but not immediately address) are
  deployment considerations -- i.e. how should the projects be structured so the
  code/config can be automated? How/where would this be deployed as an
  automation to produce updates to XML and commits to git -- I haven't been
  around for git hooks and git automation which were fairly rare and now seem
  common.

As uncommon as a project like ectorepo is, having local copies of code fitting
some ontological structure -- or at least some unchanging structure that is easy
for me to remember -- it has been infinitely valuable. The internet seems to
answer _deductive_ questions: isolate parts becoming more specific; whereas I
have questions requiring _inductive_ or [[https://en.wikipedia.org/wiki/Abductive_reasoning][abductive]] logic: combine parts and
generalize interfaces & abstractions, becoming more comprehensive.

With a large body of source you can search with regular expressions or with more
comprehensive data analysis, then questions like the following are fairly easy
to answer:

+ how do I get Jinja templates to do that?
+ WHY is this ansible role used?
+ how to you /integrate/ this? how to you glue these two ansible roles together?
+ how many different ways is this language keyword used? not the basics, but the
  one-off estoteric usages or magical one-liner usages.
+ what naming /patterns/ would you employ for ansible role/default variables?

** New Automation

For python automation scripts, Guix manifests should be used wherever
possible. This is because it's trivial to move between multiple systems where
Guix is installed.

*dir/.envrc.eg*

#+begin_example
use_guix_manifest manifest.scm
#+end_example

If this isn't practical, a Dockerfile should be used.

If for some reason a =poetry= environment is needed, then this should
suffice. The virtualenv should be created in =.venv= because I don't want
disk/inode usage to be difficult to clean up.

*dir/.envrc.eg*

#+begin_example sh
layout poetry
#+end_example

*dir/poetry.toml*

#+begin_example conf-toml
[virtualenvs]
#create = false
in-project = true
#+end_example

*** ectorepo/ectorepo

Any new automation scripting/tooling that makes it into the root of this repo is
intended to be shared across subdirectories and submodules.

This would use pyenv:

#+begin_src text :tangle .python-version
3.10.11
#+end_src

And an arbitrary virtualenv:

#+begin_src text :tangle .python-virtualenv.eg
gitrepo
#+end_src

*** org-babel based automations

These work well when the work and are a bit frustrating when they don't. They
are great for exploration.

The reason I didn't share some of the graphql logic between repos (like the TF,
ROCM and Ansible Collections repos) is because I don't want to find out that
changing one breaks others. I just want to get the examples and move on, knowing
that I can use git/repo to update what I have later. These would be useful to
bundle up into a single submodule and deploy.

*** submodule-based automations

Any /automations/ that are in their own submodule (outside of modules used for a
repo's default.xml) are intended to be deployed somewhere and thus have their
deployment versions pinned to some git tracking mechanism.

+ There should be a minimal number of these submodules and their connections to
  objects/references in other directories should be minimal as to reduce
  cognitive load when considering interdependencies.

** Old Automation
These are mainly based on my interests right now. I have very little interest in
making ectorepo a collaborative effort for managing =manifest.xml= files, as
that is mostly a personal thing for your own personal information system.

However, collaborating on tooling does interest me, particularly using
literate-programming approaches. Think =org-noter= but for programming projects
instead of PDF's. Dealing with links that don't break when using version control
is a bit of a headache, although I guess links with SHA's aren't that bad.
That's well off the path that I want to tread, though.

*** Planned =ectorepo= Manifest Repositories

+ [[https://github.com/ectorepo/x.files][Dotfiles]]
+ Emacs
+ Clojure
+ Julia
+ Arch Build System
+ Garuda
+ KDE
+ Krita
+ Nvidia/Kronos
+ Uber Engineering (vis.gl & etc)

*** Assumed Variables

You'll need to fill in these variables. The following =emacs-lisp= script will
then ingest them to make them available for the durander of the emacs session.

#+name: ectorepo-vars
|---------------+-------+-------------------------------|
| variable      | value | description                   |
|---------------+-------+-------------------------------|
| dev-home      |       | where your Google Repos live  |
| ectorepo-from |       | where you are extracting from |
|---------------+-------+-------------------------------|

For now, when you tangle, the current values of these these variables will be
used. This may cause some problems with workflow, so....

***** TODO this [[https://www.reddit.com/r/emacs/comments/6mzgkg/how_can_orgbabel_be_configured_to_set_variables/][s/o link]] may be useful for variables, although I was going to use  [[https://sachachua.com/blog/2021/04/emacs-making-a-hydra-cheatsheet-for-lispy/][sacha's approach]].

*** TODO Using A Declarative Literate Programming Approach

This is pretty straightforward, build one or more XML files from a list of text
blocks, exported to files. I'll use this to generate some of the files in the
=./examples= and =./templates= folders.

#+begin_src nxml :tangle ./templates/_remotes.xml
<manifest>
  <remote name="github"
          fetch="https://github.com" />
  <remote name="gitlab"
          fetch="https://gitlab.com" />
  <remote name="bitbucket"
          fetch="https://bitbucket.org" />
</manifest>
#+end_src

Here I am tangling directly into a git submodule, which is certainly an option. Why these repos? See for yourself [[https://github.com/ectorepo/basic-sec][a brief explanation]].

#+begin_src nxml :tangle ./basic-sec/default.xml
<manifest>
  <include name="_remotes" />
  <project path="securityonion"
           name="Security-Onion-Solutions/securityonion"
           remote="github" />
  <project path="BlackDragon"
           name="Cyber-Guy1/BlackDragon"
           remote="github" />
  <project path="selinux-chef"
           name="sous-chefs/selinux"
           remote="github" />
</manifest>
#+end_src

***** TODO get tangling working with =xml= or use text while specifying the mode

*** TODO Creating A =default.xml= From A Flat Directory Structure

#+name: ectorepo-flat
#+begin_src shell :tangle no
find $__ECTOREPO_FROM -wholename "$__ECTOREPO_FROM*/.git/config" -type f -exec cat \{\} + | grep -e "url = " | cut -f2 -d '='
#+end_src

Use it as input for a buffer or variable. If you created a variable for babel,
use it as input for another babel block or use =M-!= to feed the selected lines
from a buffer to a shell script that runs something like:

*** TODO Creating A =default.xml= From A Nested Directory Structure

When dealing with a nested directory structure, one must account for how the paths and groupnames will be reintegrated with the paths of =.git/config=. Some further filtering is necessary to eliminate git submodules.

When using literate programming, one should probably transform the list into
emacs-lisp objects (sorry about that non-emacs users LOL)

**** TODO start from here:

#+name: gitlist-tree
#+begin_src shell :tangle no :results value
find $__ECTOREPO_FROM -type f -wholename "*.git/config" -exec cat \{\} + | grep "url = " | sed -e "s/.*url = //"

#+end_src

*** TODO Using Org-Element To Generate A Manifest From Structure Under A Headline

[[https://orgmode.org/worg/dev/org-element-api.html][Org-Element]] allows you to programmatically work with the structure of org-files.
This should feel like how =treemacs= uses an org-mode buffer to edit its
declared workspaces.

*** TODO Extracting Lists of Repos From Git Forges

i.e. Git forges like Github, Bitbucket, or Gitlab.

This should use =org-babel= with =restclient= blocks and maybe some JS for JSON
processing.

*** TODO Generating A =default.xml= Using Alternatives to Repo

* Why Repo?

/As with all time-tested things/, there are several reasons providing
justification or motivation.

#+begin_quote
A corollary to the previous statement is that, without /sufficient socialized
upkeep/ to maintain a large work, what could fall apart *almost certainly* does.
It's one of the darker conclusions that some might reach when reflecting on
social cooperation while integrating both network theory and statistical models
(where social models with interdependence are more effectively approximated with
dependence than independence)
#+end_quote

In other words, as the Greeks and Buddhists recognized, chaos is the natural
state of things. Any order that arises is transient, sometimes serendipitous and
/special/. Great projects require socializing the upkeep for nurturing them as
one might tend a community garden. _When we can do this work more efficiently,
we can accomplish more collectively._ This is why, no matter how great or small,
almost all programming languages or projects eventually die (unless..)

This, in essence, is the mystery of the pyramids and, by extension, of the
sphinx. But, alas, I digress...

** Keep Those Repos Current With Minimal Effort

Simply define branches to fetch for each =<project/>= and then =repo sync=. This
tool should be considered as essential as git itself, although it is a bit of an
unnecessary abstraction early on.

And you'd prefer to avoid the whole =death by 1,000 git pulls= thing. That
usually results in termination. Politics around code reviews, pull requests and
such can be toxic, especially if some team members are well versed in declaring
githooks to notify them about specific regions of code that have changed in the
features you _planned_ on pushing quickly.

Some software developers are ASSHOLES.

** Build & Infrastructure Automation

Repo offers [[https://android.googlesource.com/tools/repo/+/HEAD/docs/repo-hooks.md][hooks]] and (with some duct tape) integration into CI systems that run
build tasks, tests and containerized applications.

If you want to understand the kind of scale and complexity that gets me going,
then i'm going to go ahead and linkdrop [[https://podcasts.apple.com/us/podcast/kubernetes-is-the-new-compute-w-rancher-labs-sheng-liang/id1140246356?i=1000465482034][this podcast]] here on the [[https://rancher.com/docs/][Rancher cloud
product]]. +Rancher+ Product X is like a glorious [[https://github.com/vcr/vcr][VCR]] in the cloud. The kind of
stuff they've done with Kubernetes is fascinating.

Imagination is a superpower. Just saying.

**** TODO Dammit, find Product X. It is a cloud instrumentation/observability product that:

+ automatically ingests HTTP traffic between Docker/Kubernetes, then
  parameterizes what it records.
+ allows developers and devops to virtualize /virtualized/ cloud environments
  (this is hard to google) on their local machines.

Ostensibly, this facilitates error tracing in development environments that are far closer to staging/production. So all the little things that can go wrong in the real-world production environment can be coaxed out in development.

Product X is not:
+ Garden.io
+ Rancher
+ Opstrace (as far as I can tell)
+ Pixie
+ Spring Cloud

The reason is because the product is like the apex of (software-defined networking) \otimes (instrumentation \oplus debugging) \otimes (docker/kubernetes/cloud), with a healthy dose of machine-learning on fairly terse/abstract Kube/Docker API requests.

** Git Worktrees For You And Me

It looks like repo doesn't integrate well with git worktrees AFAIK, which is a
real shame. Automation and worktrees are useful when contributing to a C++
project like Krita, which is over 1,000,000 lines of code.

*** TODO There may be some integration with git worktree in the Repo CLI, but it may be blown away with =repo sync=

** Manage Hundreds of Repos for Reference

Yep, =find-grep= works here. What is the substance of this =ectorepo=
organization's repositories, anyways? I want to provide a place where I can
share the tools I use to learn more faster.

I want to integrate some of my code analysis tools, literate programming style,
to org documents at the root of the manifest repos. As in human language, with
computering langauge I also have a hard time keeping track of and integrating
the vocabularly of hundreds of API's that I would like to have /zuhanden/ --
lit. ready at hand. In my own uphill battles with neurology, I have found the
following techniques invaluable:

+ UML diagrams and graphviz diagrams
+ Note-taking applications & frameworks
+ Journaling my installiations
+ Zettelkausten techniques and indexed notes

For each manifest repo in the =ectorepo= organization, there will be a
=README.org=. In here I want to document configuration/script tools to use: e.g.
[[https://gitlab.com/mtekman/elisp-depmap.el][Elisp Depmap]] to generate diagrams inline with the scripts I use to generate
them. I don't want all the babel blocks, content or results to be visible; just
some of it. There may be some langauge-specific analysis scripts I use -- e.g.
doing a =find-grep= for references to =(setq $defgroup_name-.*)= in the [[https://github.com/ectorepo/x.files][x.files
repo]], but probably more specific than that.

For each project in a manifest, I want at least a headline in a =code.org= file,
into which I can =org-capture= snippets of text to make notes. However, these notes are not to be public. For that, I will =org-refile= from the

To make matters more complicated, I want the =code.org= files for each manifest
repo to live in their own private repo, which requires something like GNU Stow.
Complicated? Yes, but it checks all the boxes. Everything is modular and lives
where it should. Further, this should support a workflow that is easy to reason
about while using a set of =org-refile= URL's that are mnemonic and right at my
fingertips.

** Orgmode and Org Roam

Applied metaphysics:
- systems of categorization/naming of URL's
- Avoiding broken links from the start
- copy in snippet from Discord

Ideally, if you're going to use =org-mode=, you want to have mentor or community
of emacs users you can lean on for guidance. The closest I have to either are
the now-burgeoning resources available on Github and Youtube. There's one
problem specific to =org-mode= though: almost everything dealing with
=org-agenda= is excluded from public repositories. So, one does not so easily
find examples of these workflows in public repos.

*** Applied metaphysics and the "hard" problems of CS

There are a few killer apps for emacs: =magit=, =org=, =org-roam=, =org-noter=
and others. I want to use them, but -- like all great copy & paste programmers
know -- with crappy automation, you had one problem and now you have one
hundred.

Think of =org-mode= like this -- the internet is the integrative right-half of
your second brain and =org-mode= is the analytic left-half. Just like resources
on the internet have locations, paths and names designated by URL's, the
resources in your org need a similar system. A significant difference is that
the headlines in your files are also part of your URL scheme.

When this naming system is inefficient or needs structural changes, you may have
quite a bit of work ahead of you. As in many cases with programming projects,
sometimes it's better to just start over.

Well that sucks... doesn't it?

Lacking experience with =org-roam=, I don't actually know the degree to which
breaking backlinks is going to be a problem -- i.e. I have _never_ had an emacs
mentor -- but I do know that relinking and file-management on my local system is
expensive. That is it is still a valid problem with =org-mode=. Just like the
design of a web-app or a blog, you want as system that is:

+ easy to type
+ mnemonic (you can remember URL's when you're drunk)
+ sociable (thus easy to describe in conversation, ideally)

And among other concerns, you need a naming convention that is fairly future
proof -- you at least need a monadic behavior which allows you ... nevermind.
You just need to have a plan for when you don't have a plan (that's a monad).

Simple... well as long as you're categorizing simple things. Your task, should
you choose to accept it is to categorize all things, even things you are
learning or that you still need to learn to need. Remember, this naming
convention is the kernel that generates the mass/inertia your personal system
must account for in the future. So poor choices early on will slow you down in
the future. What you don't know absolutely can hurt you.

Naming is one of the hardest problems in CS, as they say tongue-in-cheek.

*** A generic application of the module concept

To further complicate org-mode, you must remember that you have many =*.org=
files, but that they or their headlines can have specific purposes. e.g. emacs =org-mode= basically ships with two types of modules: =todo.org= and =notes.org=.

#+begin_quote
Literally everything else is up to you: this is a _personal_ information system.
#+end_quote

Org-mode users will want some of these files configured in =org-agenda= and
others simply available to =org-refile= to file away captured snippets.

I want to apply "modules" of org files to lists of directories. Since I want
these to exist in several places at once while being able to quickly control
what is public and what is git-ignored, then I may decide to use GNU Stow, hard
links or some other linking tool.

So there will be a =code.org= module of sorts, which I can "apply" to a
directory. There might be other modules (like a todo.org or notes.org module),
but there isn't necessarily any source code definition of an org file module,
per se. It's more of an idea motivating how i'm configuring my own org.

* Other Repo Resources

+ The [[https://android.googlesource.com/tools/repo/+/HEAD/docs/manifest-format.md][DTD definition]] for Repo's Manifest XML
+ The main Android platform [[https://android.googlesource.com/platform/manifest/][manifest]]
+ The main ChromiumOS platform [[https://chromium.googlesource.com/chromiumos/manifest/][manifest]]. Includes details on groups & multiple
  manifests.
+ [[https://www.instructables.com/Using-Googles-repo-command-in-your-own-projects/][How to set up in other new projects]]
+ [[https://docs.sel4.systems/projects/buildsystem/repo-cheatsheet.html][Google Repo cheatsheet]] from sel4 systems
+ [[https://en.wikibooks.org/wiki/Git/Submodules_and_Superprojects][git superprojects]] documentation
+ Android: [[https://source.android.com/setup/develop/repo][Repo Command Reference]]
+ Android: [[https://source.android.com/setup/develop/repo][Source Control Tools]]
+ Android: [[https://source.android.com/setup/create/coding-tasks][Source Control Workflow]]
+ [[https://github.com/canatella/repo-el][Repo.el]] for emacs, albeit a bit incomplete. There are newer branches from [[https://github.com/snogge/repo-el/][snogge/repo-el]], but they haven't been integrated into master or canatella's original project.
+ [[https://medium.com/qe-unit/how-google-does-monorepo-revisited-8c793be20344][How Google Does Monorepo (revisited)]]

** Answers To Common Google Repo Questions

My exposure to the tool is limited, but these were some of the workflow and usage questions to which I could not quickly find definitive answers.

*** Can many =*.xml= files share a repo when they do not produce a common manifest?

Yes, but it complicates things when you want to clone a manifest repo without using =repo -m $XML_FILE=.

If so, it's possible to create a repo with a bunch of these manifests and serve
them into repos... but it's not practical without an XML server.

*** Can I use symlinks?

This would help you link manifests into a single git repository. However, you end up running into the same problems. Further, linking files within a manifest repo for the Repo tool makes things a bit dicey.

So no. Just no. Technically, you can, but ... good luck. RTFM or cry.

*** What is this local manifest thing?

If like me you're searching for a way around the two problems above, then it's
probably not what you're looking for. It's useful for extending from a manifest,
but it's subclass where you want modularity or true multi-inheritence.

*** So how do I get around having one =default.xml=?

You don't. You either use git URLS, raw XML URL's or =file://= URLS. With the
last of the above, repo may not work as designed: you are venturing into
advanced use-case territory, so you should know what you're doing before you get
there -- this is what took me so damn long. The XML server option is fairly
advanced as well.

**** ... well technically, this =--standalone-manifest= may help.

#+begin_example bash
repo init -u $url -m --standalone-manifest
#+end_example

+ It works, but according to =./repo/project.py= changes to the manifest will
  only be sync'd when fully specifying the =repo sync -u $url -m $file
  --standalone-manifest=.
+ The bad news: it will run =.rmtree(...)= on =gitdir= and =worktree=, which
  blows away the git index/cache and most other things you might care about if
  you didn't push your code to remote.
  - all in all, it works as long as you know that.
  - here's an [[file:/data/ecto/guix/.repo/repo/project.py::which necessitates starting fresh.][orgit link]] (local fs) to the commit: [[orgit-rev:/data/ecto/guix/.repo/repo/::9b03f15e8e870866b26699f696af1884100f51b5][/data/ecto/guix/.repo/repo/ (magit-rev 9b03f15)]]

*** Can I use one giant manifest with Repo groups?

I didn't really think about this, but yes. However, keep in mind that doing a
=repo sync= on the ChromiumOS manifest caused my =/home= partition to run out of
disk.

*** Common scripting languages download their package sources to disk. Why not just use that?

For me, that works on a language-by-language basis, sometimes depending on the
tooling that I have configured for the language, like =nvm= or =chruby=, =rbenv=
and =ruby_build=.

You really want to designate important libraries that you care about and give
them a special place.

*** Can I branch and manage my manifest.xml's in different branches?

Don't LOL

** A Brief Liest of Alternatives to [[https://gerrit.googlesource.com/git-repo/][Google Repo]]

GLHF. You'll probably arrive at the same conclusion as I, but hopefully more
quickly: just use the software built by Google.

+ [[https://github.com/pazdera/gitwalk][pazdera/gitwalk]] (popular, allows groups defined via JSON, best so far besides repo)
+ [[https://github.com/mixu/gr][mixu/gr]] (another promising bulk management tool)
  + similar to my old ad hoc gitar scripts
  + auto-discover local git repos, attach tags and manage as lists
+ [[https://github.com/asottile/all-repos][asottile/all-repos]] (interesting)
+ [[https://github.com/naddeoa/git-bulk][naddeoa/git-bulk]] (also probably helpful)
+ [[https://github.com/fabiospampinato/autogit][fabiospampinato/autogit]] (most popular, but aimed towards personal/org repo management)
+ [[https://github.com/scivision/pygit-bulk][scivision/pygit-bulk]] and [[https://pypi.org/project/gitutils/][GitMC]]
+ [[https://gist.github.com/Lukas238/8d9abbeabfcd7225e3a254d40eb0c080][Bulk backup/clone of Git Repos From A List]]
+ [[https://github.com/taylorjayoung/RepoSweeper][RepoSweeper]] (for deleting/managing Github repos)
+ [[https://github.com/genius-systems/gameta][Gameta]] (python)
+ [[https://github.com/blejdfist/git-metarepo][git-metarepo]]
+ [[0    Link: https://gerrit.googlesource.com/git-repo/][repo]] (google)
+ [[https://fabioz.github.io/mu-repo/][murepo]]
+ [[https://github.com/mateodelnorte/meta][meta]] (node cmd & makefile approach)

* The Master/Main "Debate"

** It's Time To Put This Shit To Bed

**Too Long, Don't Care** -- =git= should probably be patched to put an end to
this /ridiculous, etymologically inaccurate fiasco/ by making main an alias to
master...

It's all for CRT mind-control word games to drive more division by triggering
thoughts in event-driven fashion at high-volumes. /All day, every day -- for
anyone who touches git./ *Somebody call Syd Barrett:* they comin' for the Pink
Floyd masters next. Your /Master's degree/? That derives from the same sense of
the etymological source as git's master, the Latin magister. No, this is
literally a CRISPR mind-control [[https://www.youtube.com/watch?v=Kilz4-SxLlw&t=115s][retrovirus]] firstmost. VP heads should be rolling
at quite a few silicon valley firms for proactively seeding division with CRT's
private little word games.

There is a difference between nouns and adjectives which denote a capacity for
agency and those which don't. In git, the adjective or adjectival noun master
does /not/ denote something with agency. In git (and afaik in source control
systems dating back to Sourcesafe) the word master is never seen opposite the
designation slave ... and in contexts where that does happen, the conventions
and norms should probably be changed. However, those are usually devices and
systems with some capacity for agency.

IMO, a resolution to the argument settled by etymology or subjective
connotations is unsatisfactory. For the designations master/slave, they do not
confer enough degrees of designation. The term root is satisfactory in its
ability to designate consensus on the original master copy of something used for
shared work -- like an original Hollywood Reel or a studio master produced by a
mastering engineer. And yes the adjectival gerund "mastering" detracts a bit
from my agent-noun argument.

But, alas, unless we plan on burning copies of the Oxford Dictionaries, we are
stuck with the English word [[https://en.wiktionary.org/wiki/master][master]], derived [[https://en.wiktionary.org/wiki/Appendix:Glossary#doublet][as a doublet]] from Italian [[https://en.wiktionary.org/wiki/maestro#Italian][maestro]]
and ultimately Latin [[https://en.wiktionary.org/wiki/magister#Latin][magister]], which thereby conferred its connotations of
record-keeping (viz. magistrate). And, please, don't make me bust out my copy of
Émile Benviniste's [[https://www.amazon.com/Dictionary-Indo-European-Concepts-Society-Benveniste/dp/0986132594/ref=sr_1_1?dchild=1&keywords=benveniste&qid=1623691293&sr=8-1][Dictionary of Indo-European Concepts of Society]] or make me
explain how the wheel's impact on the commerce of ideas implies that the
Proto-Indoeuropean language is kinda bullshit. Learn your shit before you force
all of software engineering to parameterize what could otherwise be a norm.

Main is not the proper designation for a master branch. Think of the morpheme
main as part of the term mainstream, for example. Is mainstream a master or
/root/ copy of anything? No. In the context of "mainline", the morpheme main
does confer the meaning of root. It's a mixed bag. IMO, the term root should be
used in place of both master and main. However, if you've worked in devops, then
you know that the term master or the concept of root aren't really satisfactory.

I cannot stand the marxist dialectic: I look forward to a future wherein we can
say definitively that racism is in our past. I do not want to live in a future
where we have retroactively defined projects such as =git=, =linux=, =Facebook=,
=Google=, =Ruby on Rails= et alias as part of a formerly racist culture simply
because they used the term master, outside of its agent-noun sense. Linux?
Racist?

By the way, the response to police brutality and indeed Black Lives Matter
itself was catalyzed by the democratization of /data science/. It was created in
response to government records becoming publicly available and mineable
datasets. It was always a pre-ordained development and one that was perhaps
prophesied by Sun Ra, [[https://www.weirdstudies.com/60][an African American polymath]] and unsung hero who briefly
lectured on fascinating topics at /BERKLEY/ in the early seventies. In his movie
[[https://www.imdb.com/title/tt0072195/][Space Is the Place]], Sun Ra used the double image of a playing card and
video-playing tablet device. Why? To show how violence could be videotaped and
shared -- /apparently without revealing his hand/. If police had been featured
in the video clip, then it would be too obvious that justice was coming ... and
then it never would.

Why do I care? Because norms are efficient and consensus on norms is expensive.
And also because it is the height of fraudulence for software engineering
institutions to pretend they did anything to advance African American issues by
social-engineering the normative designation of master in source control. And
none of this controversy translates well outside of America by the way. You are
out of touch. And problaly white to think that you are a hero for mainstreaming
the master/main controversy.

+ Still with me? Good.
+ Vehemently disagree with me? I don't care.
+ Happen to rename your branches to main from master? So had I.

You do you. I'll do me, but I'm not contributing my energy to this mess anymore.

**** Outdated


***** TODO Process Old Readme (Language/Topic Metaprojects)

These should include:

****** A file system path, relative to some global ~$DEV_HOME~ path

****** _Notes_ Metaprojects

To create for new metaprojects, do the following, more or less. For mu-repo to
reclone all the projects, you must configure some path-dependent rules so that
the correct =mu-repo.remote-base-url= config key is available. To retrieve this
config key from within the containing metaproject root directory, you must init
a blank repository anyways (otherwise, git will not retrieve commit keys). You
could take [[https://www.freecodecamp.org/news/how-to-handle-multiple-git-configurations-in-one-machine/][this approach]] and have git deep-merge a partial
~.gitconfig-metaproject~ config into your ~$HOME/.gitconfig~, which requires
relevent configuration being placed in two places (i.e. lines changed in
~$HOME/.gitconfig~ and the merged gitconfig in the metaproject). But, you must
create a blank repo anyways for =mu-repo= to access its config keys... so it's
best to alter the ~$METAPROJECT/.git/config~ ... which needs not be in git.
Other features of mu-repo also benefit from an arbitrary blank-repo at the
metaproject root. ~<le-sigh>~

#+begin_src shell :tangle no
# USE RELATIVE PATHS

META_PROJECT=/data/dev/nvidia
META_GROUP1=src-nvidia
META_GROUP2=src-khronos

cd $META_PROJECT
mkdir $META_GROUP1 $META_GROUP2
git init

#+end_src

******* TODO describe setting up groups :murepo:


******* TODO emacs workflow: automation of structure for projects/org/code
+ outline basic structure for capture/refile
  + manage org files, repo groups and/or metadata
  + types of projects (reference groups, work, notes, etc)
+ automation for adding to gitwalk JSON groups (of repos for reference)
  + when is it helpful to use these groups? when is it definitely overkill (i.e. much of the code i'm interested in should be easy to navigate to from a project... however, for now, i'm in unfamiliar territory with no clear way to expect which dependencies are going to exist in any project. i'm trying to avoid bad habits like googling code samples)
+ outline
